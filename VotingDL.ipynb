{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1 = pd.read_csv(\"CH1.csv\")\n",
    "ch2 = pd.read_csv(\"CH2.csv\")\n",
    "ch3 = pd.read_csv(\"CH3.csv\")\n",
    "ch4 = pd.read_csv(\"CH4.csv\")\n",
    "\n",
    "ch1_X = ch1.select_dtypes(exclude = [\"int64\", \"object\"]).copy()\n",
    "ch2_X = ch2.select_dtypes(exclude = [\"int64\", \"object\"]).copy()\n",
    "ch3_X = ch3.select_dtypes(exclude = [\"int64\", \"object\"]).copy()\n",
    "ch4_X = ch4.select_dtypes(exclude = [\"int64\", \"object\"]).copy()\n",
    "\n",
    "ch1_X.drop([\"0\"], axis = 1, inplace = True)\n",
    "ch2_X.drop([\"0\"], axis = 1, inplace = True)\n",
    "ch3_X.drop([\"0\"], axis = 1, inplace = True)\n",
    "ch4_X.drop([\"0\"], axis = 1, inplace = True)\n",
    "\n",
    "Y = ch1[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndicesToBeRemoved(data):\n",
    "    fft = data.select_dtypes(\"float64\").T\n",
    "\n",
    "    indices = np.where(np.max(fft) == np.inf)[0]\n",
    "    indices = np.concatenate((indices, np.where(data.isna().any(axis = 1))[0]))\n",
    "\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([ch1_X, ch2_X, ch3_X, ch4_X], axis = 1)\n",
    "i = getIndicesToBeRemoved(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1_X = ch1_X.drop(list(set(i))).reset_index(drop=True)\n",
    "\n",
    "currentData = pd.concat([ch2_X, ch3_X, ch4_X], axis = 1) \n",
    "currentData = currentData.drop(list(set(i))).reset_index(drop=True)\n",
    "\n",
    "Y = Y.drop(list(set(i))).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    norm = np.reshape(np.linalg.norm(data, axis = 1), (-1,1))\n",
    "\n",
    "    return data / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_flux = normalize(ch1_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_current = normalize(currentData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "flux_x_train, flux_x_test, flux_y_train, flux_y_test = train_test_split(normalized_flux, Y, test_size=0.2, random_state=0, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "current_x_train, current_x_test, current_y_train, current_y_test = train_test_split(normalized_current, Y, test_size=0.2, random_state=0, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flux Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "flux_model = Sequential([Dense(2500, activation = \"relu\"),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(1200, activation = \"relu\"),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(600, activation = \"relu\"),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(300, activation = \"relu\"),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(150, activation = \"relu\"),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(75, activation = \"relu\"),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(30, activation = \"relu\"),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(7, activation = \"softmax\")])\n",
    "\n",
    "flux_model.compile(loss=SparseCategoricalCrossentropy(), optimizer = \"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 1.7819 - accuracy: 0.2162 - val_loss: 1.5599 - val_accuracy: 0.2838\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.4966 - accuracy: 0.3296 - val_loss: 1.4108 - val_accuracy: 0.3764\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.3433 - accuracy: 0.4020 - val_loss: 1.2670 - val_accuracy: 0.4015\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.2917 - accuracy: 0.4025 - val_loss: 1.1998 - val_accuracy: 0.4208\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.2528 - accuracy: 0.4334 - val_loss: 1.2052 - val_accuracy: 0.4170\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 1.2397 - accuracy: 0.4310 - val_loss: 1.1622 - val_accuracy: 0.4382\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 1.1860 - accuracy: 0.4595 - val_loss: 1.0557 - val_accuracy: 0.5560\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.1033 - accuracy: 0.5082 - val_loss: 1.0786 - val_accuracy: 0.4942\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.0316 - accuracy: 0.5285 - val_loss: 1.0331 - val_accuracy: 0.5560\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.9899 - accuracy: 0.5531 - val_loss: 0.8673 - val_accuracy: 0.6236\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.9294 - accuracy: 0.5685 - val_loss: 1.0075 - val_accuracy: 0.4730\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.8165 - accuracy: 0.6100 - val_loss: 0.7360 - val_accuracy: 0.6834\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7462 - accuracy: 0.6327 - val_loss: 0.6839 - val_accuracy: 0.6931\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7044 - accuracy: 0.6631 - val_loss: 0.5928 - val_accuracy: 0.7297\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6667 - accuracy: 0.6848 - val_loss: 0.5693 - val_accuracy: 0.7606\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.5871 - accuracy: 0.7177 - val_loss: 0.5598 - val_accuracy: 0.7297\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.5900 - accuracy: 0.7172 - val_loss: 0.6768 - val_accuracy: 0.7220\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.6054 - accuracy: 0.7153 - val_loss: 0.4838 - val_accuracy: 0.7548\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.5018 - accuracy: 0.7543 - val_loss: 0.5442 - val_accuracy: 0.7124\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.5277 - accuracy: 0.7543 - val_loss: 0.4357 - val_accuracy: 0.7934\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7601 - val_loss: 0.5329 - val_accuracy: 0.7471\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.7852 - val_loss: 0.5682 - val_accuracy: 0.7587\n",
      "Epoch 23/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7843 - val_loss: 0.4220 - val_accuracy: 0.7780\n",
      "Epoch 24/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.7920 - val_loss: 0.4524 - val_accuracy: 0.7722\n",
      "Epoch 25/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8045 - val_loss: 0.3454 - val_accuracy: 0.8243\n",
      "Epoch 26/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8041 - val_loss: 0.6558 - val_accuracy: 0.7239\n",
      "Epoch 27/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8045 - val_loss: 0.3415 - val_accuracy: 0.8629\n",
      "Epoch 28/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8248 - val_loss: 0.3156 - val_accuracy: 0.8494\n",
      "Epoch 29/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.3055 - accuracy: 0.8374 - val_loss: 0.3312 - val_accuracy: 0.8089\n",
      "Epoch 30/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.3121 - accuracy: 0.8407 - val_loss: 0.2850 - val_accuracy: 0.8919\n",
      "Epoch 31/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.2735 - accuracy: 0.8625 - val_loss: 0.2522 - val_accuracy: 0.9054\n",
      "Epoch 32/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.3169 - accuracy: 0.8610 - val_loss: 0.4977 - val_accuracy: 0.7664\n",
      "Epoch 33/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.5103 - accuracy: 0.8002 - val_loss: 0.2514 - val_accuracy: 0.8764\n",
      "Epoch 34/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.3423 - accuracy: 0.8499 - val_loss: 0.3036 - val_accuracy: 0.8378\n",
      "Epoch 35/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.2820 - accuracy: 0.8755 - val_loss: 0.3590 - val_accuracy: 0.9073\n",
      "Epoch 36/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.2394 - accuracy: 0.8943 - val_loss: 0.2004 - val_accuracy: 0.9344\n",
      "Epoch 37/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.2321 - accuracy: 0.8948 - val_loss: 0.1664 - val_accuracy: 0.9498\n",
      "Epoch 38/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.1915 - accuracy: 0.9228 - val_loss: 0.2703 - val_accuracy: 0.9266\n",
      "Epoch 39/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.1880 - accuracy: 0.9266 - val_loss: 0.1593 - val_accuracy: 0.9402\n",
      "Epoch 40/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.2013 - accuracy: 0.9252 - val_loss: 0.2059 - val_accuracy: 0.9228\n",
      "Epoch 41/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.2234 - accuracy: 0.9122 - val_loss: 0.3492 - val_accuracy: 0.8591\n",
      "Epoch 42/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.2090 - accuracy: 0.9271 - val_loss: 0.1662 - val_accuracy: 0.9479\n",
      "Epoch 43/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.1659 - accuracy: 0.9421 - val_loss: 0.1625 - val_accuracy: 0.9363\n",
      "Epoch 44/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.2150 - accuracy: 0.9184 - val_loss: 0.2868 - val_accuracy: 0.8880\n",
      "Epoch 45/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.2271 - accuracy: 0.9199 - val_loss: 0.3554 - val_accuracy: 0.8919\n",
      "Epoch 46/50\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1413 - accuracy: 0.9493 - val_loss: 0.1823 - val_accuracy: 0.9402\n",
      "Epoch 47/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.1804 - accuracy: 0.9488 - val_loss: 0.2916 - val_accuracy: 0.9382\n",
      "Epoch 48/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.1345 - accuracy: 0.9532 - val_loss: 0.1090 - val_accuracy: 0.9517\n",
      "Epoch 49/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.1462 - accuracy: 0.9508 - val_loss: 0.3888 - val_accuracy: 0.8301\n",
      "Epoch 50/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.1422 - accuracy: 0.9527 - val_loss: 0.1680 - val_accuracy: 0.9382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3304c8e88>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flux_model.fit(flux_x_train, flux_y_train, \n",
    "                epochs = 50, \n",
    "                validation_data = [flux_x_test, flux_y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = Sequential([Dense(2500, activation = \"relu\"),\n",
    "                    Dense(1200, activation = \"relu\"),\n",
    "                    Dense(600, activation = \"relu\"),\n",
    "                    Dense(300, activation = \"relu\"),\n",
    "                    Dense(150, activation = \"relu\"),\n",
    "                    Dense(75, activation = \"relu\"),\n",
    "                    Dense(30, activation = \"relu\"),\n",
    "                    Dense(7, activation = \"softmax\")])\n",
    "\n",
    "current_model.compile(loss=SparseCategoricalCrossentropy(), optimizer = \"rmsprop\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'RMSprop/RMSprop/update_4/mul_2' defined at (most recent call last):\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2915, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Lohith\\AppData\\Local\\Temp\\ipykernel_30916\\1492068265.py\", line 3, in <module>\n      validation_data = [current_x_test, current_y_test])\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 744, in apply_gradients\n      name=name,\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 801, in _distributed_apply\n      group=False,\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 776, in apply_grad_to_update_var\n      update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py\", line 241, in _resource_apply_dense\n      var_t = var - coefficients[\"lr_t\"] * grad / (\nNode: 'RMSprop/RMSprop/update_4/mul_2'\nfailed to allocate memory\n\t [[{{node RMSprop/RMSprop/update_4/mul_2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_157839]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30916\\1492068265.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m current_model.fit(current_x_train, current_y_train,\n\u001b[0;32m      2\u001b[0m                 \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                 validation_data = [current_x_test, current_y_test])\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'RMSprop/RMSprop/update_4/mul_2' defined at (most recent call last):\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2915, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Lohith\\AppData\\Local\\Temp\\ipykernel_30916\\1492068265.py\", line 3, in <module>\n      validation_data = [current_x_test, current_y_test])\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 744, in apply_gradients\n      name=name,\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 801, in _distributed_apply\n      group=False,\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 776, in apply_grad_to_update_var\n      update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n    File \"c:\\Users\\Lohith\\miniconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py\", line 241, in _resource_apply_dense\n      var_t = var - coefficients[\"lr_t\"] * grad / (\nNode: 'RMSprop/RMSprop/update_4/mul_2'\nfailed to allocate memory\n\t [[{{node RMSprop/RMSprop/update_4/mul_2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_157839]"
     ]
    }
   ],
   "source": [
    "current_model.fit(current_x_train, current_y_train,\n",
    "                epochs = 200,\n",
    "                validation_data = [current_x_test, current_y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
